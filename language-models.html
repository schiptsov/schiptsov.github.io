<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2022-11-08 Tue 09:15 -->
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Language Models</title>
<meta name="author" content="&lt;schiptsov@gmail.com&gt;" />
<meta name="generator" content="Org Mode" />
<link rel="preconnect" href="https://fonts.googleapis.com">

<link href="https://fonts.googleapis.com/css?family=Fira Sans" rel="stylesheet">

<link href="https://fonts.googleapis.com/css?family=Fira Code" rel="stylesheet">

<link rel='stylesheet' type='text/css' href='/css/main.css'/>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href=""> UP </a>
 |
 <a accesskey="H" href="index.html"> HOME </a>
</div><div id="content" class="content">
<header>
<h1 class="title">Language Models</h1>
</header><p>
There are fundamental flaws in <i>all</i> current language models which are
based on words (or ngrams) distances.
</p>

<p>
First, when one downloads entire internet and build a huge
representation, one never captures any true aspects of underlying
reality, only some current set of beliefs about isolated aspects of it.
In other words, it is always utter bullshut, either sectarian,
religions, conspiracy or just plain bullshit.
</p>

<p>
It is worth to reiterate again - word distances (and therefore the most
likely next word in a sequence) cannot, <i>in principle</i>, capture anything
real, exactly the same way that statistics based on mere observations
cannot capture the underlying &ldquo;mechanics&rdquo; of a process.
</p>

<p>
Yes, one may prompt a GPT-3 model and get seemingly intelligent answers,
but it will be actually list <i>likehood</i>, or what the most people would
say.
</p>

<p>
This, however, is almost always bullshit. What most people would say is
never the right thing, because a real expertise is rare and it is hard
to achieve, and the voices of actual experts are always lost in the
noise.
</p>

<p>
<i>The languages models capture the current shape of the noise</i>.
</p>

<p>
Second, a human language is not being used  by humans as a medium of
accurate description of aspects of reality (a mere encoding from audio
or verbatim transmission of inner representation of accumulated and
scientifically verified knowledge). Not even textbooks are adequate.
Everything which has neen written about model-based Economics turns out
to be sectarian bullshit, for example.
</p>

<p>
So, science is still the only <i>methodology</i> (however slow and costly) to
arrive at some approximation of true knowledge (being less wrong, given
partial and imperfect information we have).
</p>

<p>
The belief that a language model can provide an insight, leave alone the
truth, is deeply delusional and contradicts the fundamental principles.
But it allows some very fluent bullshitters, like fluent Karpathy, to
have a decent living and make a lot of money.
</p>

<p>
The only thing that Karpathy got right is that a vastly complex structure
which emerge as the result of training and optimizations captures more
than a human could even comprehend (the shape of a noise).
</p>

<p>
Last but not least, they funally arrived backwards at the same
principle - that the data-sets better don&rsquo;t contain any distortions of
reality, which is exactly how biological organisms <i>prior to
language-based abstractions</i> came into being.
</p>

<p>
Another side note is the fact that these complex artifacts are &ldquo;fragile&rdquo;, and
just one node being owerwitten turns a dog in an ostrich, which
inderectly proves that it is just a vastly complex &ldquo;snapshot&rdquo;of a
current noise and underlying reality is burried even deeer underneath.
</p>
</div>
<div id="postamble" class="status">
<p class="author">Author: &lt;schiptsov@gmail.com&gt;</p>
<p class="email">Email: <a href="mailto:lngnmn2@yahoo.com">lngnmn2@yahoo.com</a></p>
<p class="date">Created: 2022-11-08 Tue 09:15</p>
</div>
</body>
</html>