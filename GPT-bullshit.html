<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2023-02-06 Mon 11:31 -->
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>GPT Bullshit all over again</title>
<meta name="author" content="&lt;schiptsov@gmail.com&gt;" />
<meta name="generator" content="Org Mode" />
<link rel="preconnect" href="https://fonts.googleapis.com">

<link href="https://fonts.googleapis.com/css?family=Fira Sans" rel="stylesheet">

<link href="https://fonts.googleapis.com/css?family=Fira Code" rel="stylesheet">

<link rel='stylesheet' type='text/css' href='/css/main.css'/>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href=""> UP </a>
 |
 <a accesskey="H" href="index.html"> HOME </a>
</div><div id="content" class="content">
<header>
<h1 class="title">GPT Bullshit all over again</h1>
</header><p>
That <code>@karpathy</code> bullshitter is trending on HN again, which is not merely annoing,
but discredits everything what is good and true about science and true
philosophy.
</p>

<p>
Lets collapse some bullshit for demonstration and teaching purposes, and we will
collapse the whole fucking cathedral of bullshit by pointing at flaws in the
foundation.
</p>

<p>
To accomplish this we have to use lots of metaphors as generalizations and
references to different fields, which, of course, unlike abstract models,
converge to <i>What Is</i>.
</p>

<p>
There are thousands of years of mathematics philosophy of Mind in the East and
logic in the West, and some results they have produced are <i>valid captured
generalizations</i>, which cannot be just dismissed or brushed under the rug..
</p>

<p>
What is the mind and language in principle (what questions!). Well,
operationally, the mind is an <i>observer</i> witch continuously build and maintain an
inner representing of its environment and uses this representation for taking
actions.
</p>

<p>
This is, of course, the generalization from the studies of intelligent agents.
What is important, however, that such generalizations are not wrong, just too
general. They abstract away the specifics and actual &ldquo;implementation&rdquo;.
</p>

<p>
These inner representations are not being built each time from scratch, on the
contrary, the <i>structural template</i> of brain regions has been evolved for millions
of years and its reflects the constraints of the environment in which it happen
to evolve.
</p>

<p>
Again, the <i>structure</i> is not arbitrary it converges gradually to match What Is
out there.
</p>

<p>
A language began as a <i>medium of communication</i>, and it was an encoding for
signaling and transmission between individuals. Gradually, it became the medium
of a reasoning a &ldquo;storage&rdquo; of a shared culture, which is emerged due to use of a
common language.
</p>

<p>
Notice that neither the inner representation, not the language itself is
&ldquo;knowledge&rdquo;. It is a heavy overloaded world.
</p>

<p>
Early NLP guys came up with a simple model of communication, where parts of the
inner representation are encoded for verbal (oral or written) communication (due
to some neurochemical spikes). The communication is usually augmented by
non-verbal emotional cues - volume, pitch, gestures, and it can be emotionally
charged by using some common idioms (offensive or even obscene).
</p>

<p>
Again, there are valid generalizations, they are not wrong, they has been
&ldquo;evolved&rdquo;. These are fragments of a partially solved Jigsaw puzzle,
a multidimetional one, which can be partially solved at different scales. (this
is another metaphor, of course).
</p>

<p>
Solving a Jigsaw puzzle is the best known metaphor about the true knowledge
acquisition. There is an actual environment in which we are, and that
environment is in turn a particular locality in what we call the Universe, which
in turn, is a partially observed by the Mind manifestation of What Is.
</p>

<p>
The ability to zoom in and out through these levels of generalizations and valid
abstractions (acquired as &ldquo;knowledge&rdquo;) is what constitutes an intelligence. An
intelligent agent, again, is a process that acts according to its internal
representation of the environment. The less distortion - the better for it.
</p>

<p>
Mathematics is a set of valid generalizations and useful abstractions made by
the mind of an external observer, who observers (and generalizes from) the
actual <i>patterns</i> in What Is. The &ldquo;laws&rdquo; of arithmetic are the observed properties
of What Is. The addition is generalization of putting together (being in the
same locality) and so on.
</p>

<p>
To do mathematics the Mind does &ldquo;classification&rdquo; (pattern-recognition and
labeling and grouping). Arguably pattern-recognition, grouping and
identification (dogs know each other) is an animal mind, while labeling is an activity which requires
the language centers.
</p>

<p>
What we call logic just arises naturally. It is just a discipline of a correct
labeling and of using a human language unambiguously. The best thinkers of all
times wrestled with imperfections of a language and of the Mind. They got some
important results.
</p>

<p>
The must fundamental is that <i>just one single flawed statement or a wrong
premise collapses everything that follows (based on) it</i>.
</p>

<p>
This is what any language model lacks in principle - the actual validation of
all the previous steps (or structures).
</p>

<p>
The process of construction of a representation must be different (and it is
well-known) - each change must trigger a verification process of the whole
structure, and everything &ldquo;above a flaw&rdquo; has to be demolished (backtracking).
</p>

<p>
Now, <code>@karpathy</code>, fanboys and believers, pay attention - the back-propagation process
never eliminates wrong structures. It may diminish the weights, but it does not
collapse the structure as it should. Collapsing, demolision is required.
</p>

<p>
The problem is in terminology. What you call &ldquo;validation&rdquo; is not validation,
what you call &ldquo;backprob&rdquo; is not actual backtracking to the last valid state (in
which partial Jigsaw puzzle is valid and verified). What  you have is not a
&ldquo;knowledge representation&rdquo; it is not even &ldquo;knowledge&rdquo;. It is <i>information</i>.
</p>

<p>
<i>Information is not knowledge</i>. Pay attention here. This result is as old as
humanity itself.
</p>

<p>
What you manipulate and transform is information, not knowledge. Knowledge is
prior to information about it. Knowledge extraction requires validation and
verification of the whole at each step. There is no other way or shortcuts, in
principle.
</p>

<p>
Knowledge is What Is, and the information is mostly bullshit. Here is how.
</p>

<p>
Recall when you have joking with Friedman about <i>prompting</i> each other. So clever,
top &ldquo;data scientists&rdquo; are joking.
</p>

<p>
But that prompting is a synonym for a <i>bullshit retrieval</i> and has nothing to do
with knowledge. It is information, encoded for communication, based on a inner
representation of some individual. Giving the social and cultural forces which
shape this representation, it is guaranteed to be bullshit.
</p>

<p>
Having a less wrong representation, leave alone better solved Jigsaw, is
extremely rare, as rare as the Buddha. Some other metaphors are required to
explain.
</p>

<p>
You could &ldquo;prompt&rdquo; an African shaman or, even better - a Western &ldquo;scholar&rdquo; of a
Tibetan tantric tradition (almost entirely made up by Western scholars), and
retrieve what seems to be a &ldquo;knowledge&rdquo;. This &ldquo;seems to be&rdquo; is the key to
understanding of what is going on really.
</p>

<p>
Imagine a rubble of an ancient city. This is what your actual &ldquo;representation&rdquo;
looks like due to continuous intense bombardment with outside bullshit. The
whole atmosphere (with its rains and tornadoes) of bullshit.
</p>

<p>
When you train a GPT model on camera, you are capturing the shape of that
constantly chaining rubble, assuming you are not losing the information (which
you do by averaging). But it is not a rubble of a single individual&rsquo;s bullshit,
it is a snapshot of written bullshit of millions of individuals, put <i>through a
shreder</i>.
</p>

<p>
Yes, splitting into ngrams is exactly putting the texts throng a shreder before
reading them. This is a valid metaphor. Why? Because knowledge is <i>not encoded at
this level</i>. It is not even at the level of nouns and verbs. <i>It is not at the
level of a particular language</i>. Any of 6000 of human languages can be used to encode a
verbalized metaphor more or less wrong.
</p>

<p>
The knowledge is at the level <i>prior to any language</i>.
</p>

<p>
Now what is that you <i>retrieve</i>. You retrieve structures (information) which look like (to you
and the others) as a &ldquo;knowledge&rdquo;. It passes tests of being well-formed
sentences, and some <i>sematical heuristics</i> (seems legit LOL).
</p>

<p>
The problem is that this is definition of a <i>sectarian bullshit</i>, conspiracy and
abstract theories, religious beliefs, and any other kind of a familar bullshit.
</p>

<p>
Do you remember what mathematicians, logicians and early scientists of the past
were tried to do? They tried to discard and prune out bullshit. What you do is
producing and multiplying bullshit. Exactly, literally, in principle, by
definition. Mere words is not a knowledge.
</p>

<p>
By now even an ordinary reader would see <i>why</i>.
</p>

<p>
Mere observations and descriptive statistics is not enough to understand and to know
the underlying causal relations. Controlled experiments and reduction of the
results to what is already known (non-contradiction) - to the partially solved
Jigsaw puzzle is the process of knowledge extractions.
</p>

<p>
It is the process <i>of removing the bullshit to see what remains</i>. You are doing
the opposite with your models.
</p>

<p>
Now what is the whole process than? Well, the usual shamanistic rithuals to
impress the public. Cosplay of intelligence, cosplay of being super smart,
cosplay of being way above average, instead of actually being less wrong.
</p>
</div>
<div id="postamble" class="status">
<p class="author">Author: &lt;schiptsov@gmail.com&gt;</p>
<p class="email">Email: <a href="mailto:lngnmn2@yahoo.com">lngnmn2@yahoo.com</a></p>
<p class="date">Created: 2023-02-06 Mon 11:31</p>
</div>
</body>
</html>